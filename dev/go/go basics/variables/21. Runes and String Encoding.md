In programming languages like C, a "character" is a single byte. Using [ASCII](https://www.asciitable.com/) encoding, the standard for the C programming language, we can represent 128 characters with 7 bits. This is enough for the English alphabet, numbers, and some special characters.

In Go, strings are just sequences of bytes: they can hold arbitrary data. However, Go also has a special type, [rune](https://go.dev/blog/strings), which is an alias for `int32`. This means that a `rune` is a 32-bit integer, which is large enough to hold any [Unicode](https://home.unicode.org/) code point.

When you're working with strings, you need to be aware of the encoding (bytes -> representation). Go uses [UTF-8](https://en.wikipedia.org/wiki/UTF-8), which is a variable-length encoding.

So, there are 2 main takeaways:
1. When you need to work with individual characters in a string, you should use the `rune` type. It breaks strings up into their individual characters, which can be more than one byte long.
2. We can use [zany](https://www.merriam-webster.com/dictionary/zany) characters like emojis and Chinese characters in our strings, and Go will handle them just fine.

Take a look at this.
```go
package main

import (
	"fmt"
	"unicode/utf8"		
)

func main(){
	const name = "bear"
	fmt.Printf("constant 'name' byte length: ", len(name))
	fmt.Printf("constant 'name' rune length: ", utf8.RuneCountInString(name))
}
```
If we run the code, we get
```
constant 'name' byte length: 4
constant 'name' rune length: 4
```

What if we change `"bear"` with `"üêª"`

We get
```
constant 'name' byte length: 4
constant 'name' rune length: 1
```
